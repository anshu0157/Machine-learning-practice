{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_diabetes\n",
    "#Importing regression models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019908 -0.017646   151.0  \n",
       "1   -0.039493 -0.068330 -0.092204    75.0  \n",
       "2   -0.002592  0.002864 -0.025930   141.0  \n",
       "3    0.034309  0.022692 -0.009362   206.0  \n",
       "4   -0.002592 -0.031991 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018118  0.044485   104.0  \n",
       "439 -0.011080 -0.046879  0.015491   132.0  \n",
       "440  0.026560  0.044528 -0.025930   220.0  \n",
       "441 -0.039493 -0.004220  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab=load_diabetes()\n",
    "df = pd.DataFrame(data= np.c_[diab['data'], diab['target']],\n",
    "                     columns= diab['feature_names'] + ['target'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04,  0.05,  0.06, ..., -0.  ,  0.02, -0.02],\n",
       "       [-0.  , -0.04, -0.05, ..., -0.04, -0.07, -0.09],\n",
       "       [ 0.09,  0.05,  0.04, ..., -0.  ,  0.  , -0.03],\n",
       "       ...,\n",
       "       [ 0.04,  0.05, -0.02, ..., -0.01, -0.05,  0.02],\n",
       "       [-0.05, -0.04,  0.04, ...,  0.03,  0.04, -0.03],\n",
       "       [-0.05, -0.04, -0.07, ..., -0.04, -0.  ,  0.  ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=load_diabetes(return_X_y=1)\n",
    "#y=y.reshape(len(y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of null values in x: 0\n",
      "No. of Null values in y: 0\n"
     ]
    }
   ],
   "source": [
    "print('No. of null values in x:',np.isnan(x).any().sum())\n",
    "print('No. of Null values in y:',np.isnan(y).any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 78. 152. 200.  59. 311. 178. 332. 132. 156. 135. 220. 233.  91.  51.\n",
      " 195. 109. 217.  94.  89. 111. 129. 181. 168.  97. 115. 202.  84. 147.\n",
      " 253. 144. 262. 115.  68.  65. 252. 212. 142. 215. 180. 163. 151. 283.\n",
      "  66.  83. 214. 189. 302.  93. 178. 241.  52. 144. 102. 200. 232.  97.\n",
      " 109.  55.  63.  98.  88. 233. 235.  97. 243.  59. 138. 220. 137.  72.\n",
      " 109.  71.  74. 219. 196. 170. 199.  71. 155.  52.  63.  88.  97. 100.\n",
      "  64. 107.  49.  60. 346.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=1)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiple linear regression\n",
    "reg1=LinearRegression()\n",
    "reg1.fit(x_train,y_train)\n",
    "#Decision tree regression\n",
    "reg2=DecisionTreeRegressor()\n",
    "reg2.fit(x_train,y_train)\n",
    "#Random forest regression\n",
    "reg3=RandomForestRegressor(n_estimators=100,random_state=1)\n",
    "reg3.fit(x_train,y_train)\n",
    "#Polynomial regression\n",
    "poly_reg=PolynomialFeatures(degree=5)\n",
    "x_poly=poly_reg.fit_transform(x_train)\n",
    "reg4=LinearRegression()\n",
    "reg4.fit(x_poly,y_train)\n",
    "#Support vector regression\n",
    "reg5=SVR(kernel='rbf')\n",
    "reg5.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.80e+01  1.19e+02  9.50e+01  1.35e+02 -3.49e+02  1.35e+02]\n",
      " [ 1.52e+02  1.11e+02  7.70e+01  1.09e+02  7.75e+01  1.32e+02]\n",
      " [ 2.00e+02  1.85e+02  9.60e+01  1.57e+02  4.26e+02  1.44e+02]\n",
      " [ 5.90e+01  6.80e+01  9.30e+01  7.92e+01  1.92e+02  1.19e+02]\n",
      " [ 3.11e+02  1.71e+02  1.64e+02  1.49e+02  2.44e+02  1.55e+02]\n",
      " [ 1.78e+02  1.90e+02  2.97e+02  2.53e+02  2.19e+02  1.55e+02]\n",
      " [ 3.32e+02  2.19e+02  2.37e+02  2.14e+02  1.40e+02  1.63e+02]\n",
      " [ 1.32e+02  1.20e+02  4.90e+01  9.17e+01  2.02e+02  1.33e+02]\n",
      " [ 1.56e+02  1.57e+02  2.52e+02  1.47e+02 -4.83e+02  1.38e+02]\n",
      " [ 1.35e+02  1.29e+02  1.18e+02  9.10e+01  1.07e+02  1.28e+02]\n",
      " [ 2.20e+02  2.14e+02  2.72e+02  1.87e+02  1.06e+01  1.52e+02]\n",
      " [ 2.33e+02  2.03e+02  1.71e+02  1.95e+02  9.98e+02  1.52e+02]\n",
      " [ 9.10e+01  8.84e+01  1.18e+02  1.07e+02  2.05e+02  1.25e+02]\n",
      " [ 5.10e+01  7.20e+01  9.20e+01  9.27e+01  3.18e+02  1.22e+02]\n",
      " [ 1.95e+02  2.37e+02  2.97e+02  2.65e+02  3.75e+02  1.58e+02]\n",
      " [ 1.09e+02  2.06e+02  2.81e+02  2.13e+02  1.52e+02  1.54e+02]\n",
      " [ 2.17e+02  1.76e+02  1.98e+02  1.87e+02  4.09e+02  1.50e+02]\n",
      " [ 9.40e+01  1.02e+02  6.00e+01  8.88e+01 -1.75e+01  1.24e+02]\n",
      " [ 8.90e+01  1.14e+02  2.30e+02  1.11e+02 -1.63e+02  1.44e+02]\n",
      " [ 1.11e+02  1.69e+02  2.10e+02  1.91e+02  1.42e+02  1.47e+02]\n",
      " [ 1.29e+02  1.88e+02  2.81e+02  1.64e+02  1.95e+02  1.56e+02]\n",
      " [ 1.81e+02  8.56e+01  1.82e+02  7.88e+01  1.59e+01  1.17e+02]\n",
      " [ 1.68e+02  1.44e+02  1.50e+02  9.96e+01  2.33e+02  1.30e+02]\n",
      " [ 9.70e+01  1.07e+02  1.37e+02  1.13e+02  9.93e+01  1.29e+02]\n",
      " [ 1.15e+02  9.40e+01  7.70e+01  9.95e+01  9.87e+01  1.20e+02]\n",
      " [ 2.02e+02  2.12e+02  1.98e+02  2.22e+02  4.08e+02  1.53e+02]\n",
      " [ 8.40e+01  9.07e+01  1.14e+02  9.53e+01  9.10e+01  1.20e+02]\n",
      " [ 1.47e+02  1.76e+02  1.98e+02  1.35e+02  9.10e+01  1.39e+02]\n",
      " [ 2.53e+02  1.23e+02  1.04e+02  1.20e+02 -2.37e+02  1.43e+02]\n",
      " [ 1.44e+02  1.81e+02  1.63e+02  1.97e+02  2.64e+02  1.55e+02]\n",
      " [ 2.62e+02  1.57e+02  1.79e+02  1.45e+02 -2.06e+01  1.48e+02]\n",
      " [ 1.15e+02  1.38e+02  6.70e+01  1.66e+02 -9.83e+01  1.43e+02]\n",
      " [ 6.80e+01  1.92e+02  1.92e+02  2.03e+02  4.40e+02  1.48e+02]\n",
      " [ 6.50e+01  9.45e+01  2.00e+02  1.10e+02  3.03e+02  1.24e+02]\n",
      " [ 2.52e+02  1.66e+02  9.00e+01  1.61e+02 -7.99e+02  1.38e+02]\n",
      " [ 2.12e+02  1.89e+02  1.92e+02  1.89e+02  2.19e+02  1.59e+02]\n",
      " [ 1.42e+02  1.11e+02  2.14e+02  1.32e+02 -5.06e+02  1.31e+02]\n",
      " [ 2.15e+02  2.48e+02  1.66e+02  2.21e+02  1.05e+02  1.63e+02]\n",
      " [ 1.80e+02  1.72e+02  1.64e+02  1.51e+02 -6.45e+01  1.49e+02]\n",
      " [ 1.63e+02  1.88e+02  1.07e+02  1.77e+02  4.29e+00  1.51e+02]\n",
      " [ 1.51e+02  1.60e+02  2.10e+02  1.84e+02  3.47e+02  1.39e+02]\n",
      " [ 2.83e+02  1.77e+02  1.61e+02  1.88e+02 -1.18e+03  1.44e+02]\n",
      " [ 6.60e+01  1.16e+02  2.30e+02  1.30e+02  2.36e+02  1.31e+02]\n",
      " [ 8.30e+01  1.20e+02  1.60e+02  1.14e+02  2.43e+02  1.30e+02]\n",
      " [ 2.14e+02  1.42e+02  1.54e+02  1.22e+02  2.15e+02  1.31e+02]\n",
      " [ 1.89e+02  2.03e+02  9.00e+01  1.88e+02 -3.75e+02  1.53e+02]\n",
      " [ 3.02e+02  1.52e+02  1.29e+02  1.63e+02  7.18e+02  1.34e+02]\n",
      " [ 9.30e+01  1.44e+02  1.62e+02  1.50e+02  5.22e+01  1.33e+02]\n",
      " [ 1.78e+02  1.90e+02  1.82e+02  1.47e+02 -7.56e-01  1.53e+02]\n",
      " [ 2.41e+02  1.91e+02  2.81e+02  1.72e+02 -6.06e+02  1.56e+02]\n",
      " [ 5.20e+01  5.98e+01  7.50e+01  6.32e+01  2.60e+02  1.16e+02]\n",
      " [ 1.44e+02  1.60e+02  1.45e+02  1.30e+02 -1.38e+02  1.44e+02]\n",
      " [ 1.02e+02  1.02e+02  6.50e+01  9.08e+01 -2.17e+01  1.30e+02]\n",
      " [ 2.00e+02  1.48e+02  8.60e+01  1.34e+02  1.98e+02  1.33e+02]\n",
      " [ 2.32e+02  1.86e+02  1.63e+02  2.05e+02  1.87e+02  1.56e+02]\n",
      " [ 9.70e+01  1.21e+02  7.10e+01  1.06e+02  1.64e+02  1.33e+02]\n",
      " [ 1.09e+02  1.59e+02  7.30e+01  1.45e+02 -3.54e+02  1.41e+02]\n",
      " [ 5.50e+01  8.34e+01  5.00e+01  7.86e+01 -3.25e+01  1.25e+02]\n",
      " [ 6.30e+01  5.56e+01  7.00e+01  6.47e+01  7.91e+01  1.20e+02]\n",
      " [ 9.80e+01  7.91e+01  7.50e+01  8.62e+01 -4.27e+01  1.20e+02]\n",
      " [ 8.80e+01  9.95e+01  6.90e+01  1.27e+02  2.28e+02  1.27e+02]\n",
      " [ 2.33e+02  2.00e+02  1.39e+02  2.15e+02  9.18e+02  1.49e+02]\n",
      " [ 2.35e+02  1.69e+02  2.10e+02  1.68e+02  4.63e+02  1.46e+02]\n",
      " [ 9.70e+01  1.09e+02  8.70e+01  8.59e+01  1.12e+02  1.24e+02]\n",
      " [ 2.43e+02  2.76e+02  2.63e+02  2.50e+02 -5.06e+01  1.57e+02]\n",
      " [ 5.90e+01  7.65e+01  7.50e+01  7.51e+01 -1.08e+02  1.17e+02]\n",
      " [ 1.38e+02  7.41e+01  3.10e+01  7.10e+01 -4.95e+01  1.17e+02]\n",
      " [ 2.20e+02  1.68e+02  1.21e+02  2.07e+02  7.91e+02  1.45e+02]\n",
      " [ 1.37e+02  1.98e+02  1.92e+02  2.11e+02  4.00e+02  1.48e+02]\n",
      " [ 7.20e+01  5.88e+01  5.20e+01  7.42e+01  2.74e+02  1.21e+02]\n",
      " [ 1.09e+02  1.64e+02  6.70e+01  1.50e+02  2.79e+03  1.45e+02]\n",
      " [ 7.10e+01  8.74e+01  1.01e+02  1.18e+02  3.95e+02  1.29e+02]\n",
      " [ 7.40e+01  8.96e+01  8.80e+01  9.89e+01 -1.78e+02  1.27e+02]\n",
      " [ 2.19e+02  1.36e+02  1.50e+02  1.13e+02  1.03e+02  1.33e+02]\n",
      " [ 1.96e+02  1.59e+02  2.79e+02  1.49e+02  1.37e+02  1.47e+02]\n",
      " [ 1.70e+02  9.43e+01  9.40e+01  1.15e+02  3.90e+02  1.32e+02]\n",
      " [ 1.99e+02  1.08e+02  2.30e+02  1.03e+02  2.65e+02  1.33e+02]\n",
      " [ 7.10e+01  8.56e+01  4.30e+01  8.25e+01  8.84e+01  1.24e+02]\n",
      " [ 1.55e+02  2.23e+02  2.93e+02  2.42e+02  1.98e+02  1.59e+02]\n",
      " [ 5.20e+01  1.77e+02  1.18e+02  1.84e+02  5.14e+02  1.40e+02]\n",
      " [ 6.30e+01  1.00e+02  7.70e+01  1.05e+02 -2.82e+01  1.22e+02]\n",
      " [ 8.80e+01  1.11e+02  4.40e+01  1.02e+02  9.49e+01  1.24e+02]\n",
      " [ 9.70e+01  1.50e+02  2.14e+02  1.19e+02  5.44e+01  1.33e+02]\n",
      " [ 1.00e+02  1.52e+02  1.79e+02  1.40e+02  1.81e+02  1.51e+02]\n",
      " [ 6.40e+01  1.13e+02  9.30e+01  9.23e+01 -3.64e+02  1.25e+02]\n",
      " [ 1.07e+02  1.11e+02  1.11e+02  1.02e+02  1.17e+02  1.34e+02]\n",
      " [ 4.90e+01  9.84e+01  7.90e+01  8.80e+01  2.34e+02  1.21e+02]\n",
      " [ 6.00e+01  7.31e+01  7.70e+01  8.61e+01  3.33e+02  1.27e+02]\n",
      " [ 3.46e+02  2.71e+02  9.10e+01  1.68e+02 -2.21e+03  1.50e+02]]\n"
     ]
    }
   ],
   "source": [
    "y_pred1=reg1.predict(x_test)\n",
    "y_pred2=reg2.predict(x_test)\n",
    "y_pred3=reg3.predict(x_test)\n",
    "y_pred4=reg4.predict(poly_reg.transform(x_test))\n",
    "y_pred5=reg5.predict(x_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_test.reshape(len(y_test),1),y_pred1.reshape(len(y_pred1),1),y_pred2.reshape(len(y_pred2),1),\n",
    "                      y_pred3.reshape(len(y_pred3),1),y_pred4.reshape(len(y_pred4),1),y_pred5.reshape(len(y_pred5),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear regression accuracy: 0.43843604017332694\n",
      "Decision tree regression accuracy: -0.23373117962726786\n",
      "Random forest regression accuracy: 0.2837289750645179\n",
      "Polynomial regression accuracy: -48.115561041813535\n",
      "Support vector regression accuracy: 0.17710151701511323\n"
     ]
    }
   ],
   "source": [
    "print('Multiple linear regression accuracy:',r2_score(y_test,y_pred1))\n",
    "print('Decision tree regression accuracy:',r2_score(y_test,y_pred2))\n",
    "print('Random forest regression accuracy:',r2_score(y_test,y_pred3))\n",
    "print('Polynomial regression accuracy:',r2_score(y_test,y_pred4))\n",
    "print('Support vector regression accuracy:',r2_score(y_test,y_pred5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([203.36])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1.predict([[0.038076 ,0.050680,0.061696,0.021872,-0.044223,-0.034821,-0.043401,-0.002592,0.019908,-0.017646]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
